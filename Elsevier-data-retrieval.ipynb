{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now provide the Elsevier API key and the query. API key can be found [here](https://dev.elsevier.com/apikey/manage). \n",
    "\n",
    "Query is constructed as described in the Elsevier instructions.\n",
    "Boolean logic applies. Use AND to find both occurrences of the keywords, OR to find either occurrence and NOT to exclude a keyword. You can find detailed information [here](https://service.elsevier.com/app/answers/detail/a_id/25974/supporthub/sciencedirect/).\n",
    "\n",
    "Example:\n",
    "\n",
    "*(“market share” OR “leisure tourism”) AND stakeholders AND NOT space*\n",
    "\n",
    "will return articles that contain keywords \"market share stakeholders\" or \"leisure toursim stakeholders\", but never the keyword \"space\". Please note that you need to use quotation marks to browse by phrase, e.g. \"tourism research\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIKey = \"\"\n",
    "query = \"tourism+AND+innovation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the data structure with the following attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Title': [],\n",
    "        'Authors': [],\n",
    "        'PublicationName': [],\n",
    "        'Type': [],\n",
    "        'Abstract': [],\n",
    "        'Content': [],\n",
    "        'Volume': [],\n",
    "        'Issue': [],\n",
    "        'Date': [],\n",
    "        'Pages': [],\n",
    "        'PII': [],\n",
    "        'Keywords' : [],\n",
    "        'URL' : [],\n",
    "        'OpenAccess': [],\n",
    "        'References': [],\n",
    "        'CitedBy': [],\n",
    "        'AuthorAUID': [],\n",
    "        'AuthKeywords': [],\n",
    "        'SubjectAreas': []\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we retrieve 6000 articles from Elsevier and parse them on the fly. We use Scopus to get 'cited by' information and keywords.\n",
    "\n",
    "We also print progress as we go (at every 25th instance checked)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "400\n",
      "425\n",
      "450\n",
      "475\n",
      "500\n",
      "525\n",
      "550\n",
      "575\n",
      "600\n",
      "625\n",
      "650\n",
      "675\n",
      "700\n",
      "725\n",
      "750\n",
      "775\n",
      "800\n",
      "825\n",
      "850\n",
      "875\n",
      "900\n",
      "925\n",
      "950\n",
      "975\n",
      "1000\n",
      "1025\n",
      "1050\n",
      "1075\n",
      "1100\n",
      "1125\n",
      "1150\n",
      "1175\n",
      "1200\n",
      "1225\n",
      "1250\n",
      "1275\n",
      "1300\n",
      "1325\n",
      "1350\n",
      "1375\n",
      "1400\n",
      "1425\n",
      "1450\n",
      "1475\n",
      "1500\n",
      "1525\n",
      "1550\n",
      "1575\n",
      "1600\n",
      "1625\n",
      "1650\n",
      "1675\n",
      "1700\n",
      "1725\n",
      "1750\n",
      "1775\n",
      "1800\n",
      "1825\n",
      "1850\n",
      "1875\n",
      "1900\n",
      "1925\n",
      "1950\n",
      "1975\n",
      "2000\n",
      "2025\n",
      "2050\n",
      "2075\n",
      "2100\n",
      "2125\n",
      "2150\n",
      "2175\n",
      "2200\n",
      "2225\n",
      "2250\n",
      "2275\n",
      "2300\n",
      "2325\n",
      "2350\n",
      "2375\n",
      "2400\n",
      "2425\n",
      "2450\n",
      "2475\n",
      "2500\n",
      "2525\n",
      "2550\n",
      "2575\n",
      "2600\n",
      "2625\n",
      "2650\n",
      "2675\n",
      "2700\n",
      "2725\n",
      "2750\n",
      "2775\n",
      "2800\n",
      "2825\n",
      "2850\n",
      "2875\n",
      "2900\n",
      "2925\n",
      "2950\n",
      "2975\n",
      "3000\n",
      "3025\n",
      "3050\n",
      "3075\n",
      "3100\n",
      "3125\n",
      "3150\n",
      "3175\n",
      "3200\n",
      "3225\n",
      "3250\n",
      "3275\n",
      "3300\n",
      "3325\n",
      "3350\n",
      "3375\n",
      "3400\n",
      "3425\n",
      "3450\n",
      "3475\n",
      "3500\n",
      "3525\n",
      "3550\n",
      "3575\n",
      "3600\n",
      "3625\n",
      "3650\n",
      "3675\n",
      "3700\n",
      "3725\n",
      "3750\n",
      "3775\n",
      "3800\n",
      "3825\n",
      "3850\n",
      "3875\n",
      "3900\n",
      "3925\n",
      "3950\n",
      "3975\n",
      "4000\n",
      "4025\n",
      "4050\n",
      "4075\n",
      "4100\n",
      "4125\n",
      "4150\n",
      "4175\n",
      "4200\n",
      "4225\n",
      "4250\n",
      "4275\n",
      "4300\n",
      "4325\n",
      "4350\n",
      "4375\n",
      "4400\n",
      "4425\n",
      "4450\n",
      "4475\n",
      "4500\n",
      "4525\n",
      "4550\n",
      "4575\n",
      "4600\n",
      "4625\n",
      "4650\n",
      "4675\n",
      "4700\n",
      "4725\n",
      "4750\n",
      "4775\n",
      "4800\n",
      "4825\n",
      "4850\n",
      "4875\n",
      "4900\n",
      "4925\n",
      "4950\n",
      "4975\n",
      "5000\n",
      "5025\n",
      "5050\n",
      "5075\n",
      "5100\n",
      "5125\n",
      "5150\n",
      "5175\n",
      "5200\n",
      "5225\n",
      "5250\n",
      "5275\n",
      "5300\n",
      "5325\n",
      "5350\n",
      "5375\n",
      "5400\n",
      "5425\n",
      "5450\n",
      "5475\n",
      "5500\n",
      "5525\n",
      "5550\n",
      "5575\n",
      "5600\n",
      "5625\n",
      "5650\n",
      "5675\n",
      "5700\n",
      "5725\n",
      "5750\n",
      "5775\n",
      "5800\n",
      "5825\n",
      "5850\n",
      "5875\n",
      "5900\n",
      "5925\n",
      "5950\n",
      "5975\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 6000, 25):\n",
    "    print(i)\n",
    "    response = requests.get(\n",
    "        \"https://api.elsevier.com/content/search/sciencedirect?query={}&apiKey={}&start={}\".format(query, APIKey, i))\n",
    "    cont = json.loads(response.content)\n",
    "    for i in cont[\"search-results\"][\"entry\"]:\n",
    "        url = i['prism:url']\n",
    "        data['URL'].append(str(url))\n",
    "        article = requests.get(\"{}?apiKey={}\".format(url, APIKey))\n",
    "        soup = Soup(article.content, features=\"lxml\")\n",
    "        \n",
    "        data['Title'].append(soup.find('dc:title').get_text().replace('\\n', ' ') if soup.find('dc:title') else '')\n",
    "        authors = soup.find_all('dc:creator')\n",
    "        data['Authors'].append('; '.join([item.get_text() for item in authors]) if authors else '')\n",
    "        data['PublicationName'].append(soup.find('prism:publicationname').get_text() if \n",
    "                                        soup.find('prism:publicationname') else '')\n",
    "        data['Type'].append(soup.find('prism:aggregationtype').get_text() if\n",
    "                            soup.find('prism:aggregationtype') else '')\n",
    "        data['Abstract'].append(soup.find('dc:description').get_text().replace('\\n', ' ') \n",
    "                                if soup.find('dc:description') else '')\n",
    "        data['Content'].append(soup.find('ce:sections').get_text().replace('\\n', ' ') \n",
    "                               if soup.find('ce:sections') else '')\n",
    "        data['Volume'].append(soup.find('prism:volume').get_text() if soup.find('prism:volume') else '')\n",
    "        data['Issue'].append(soup.find('prism:issueidentifier').get_text() \n",
    "                             if soup.find('prism:issueidentifier') else '')\n",
    "        data['Date'].append(soup.find('prism:coverdate').get_text() if soup.find('prism:coverdate') else '')\n",
    "        data['Pages'].append(soup.find('prism:pagerange').get_text() if soup.find('prism:pagerange') else '')\n",
    "        data['PII'].append(soup.find('pii').get_text() if soup.find('pii') else '')\n",
    "        data['Keywords'].append('; '.join([res.get_text() for res in soup.find_all('dcterms:subject')] \n",
    "                                          if soup.find_all('dcterms:subject') else ''))\n",
    "        data['OpenAccess'].append(soup.find('openaccess').get_text())\n",
    "        labels = soup.find_all('ce:label')\n",
    "        data['References'].append('; '.join([label.get_text() for label in soup.find_all('ce:label') \n",
    "                                             if label.parent.name == 'ce:bib-reference']) \n",
    "                                  if soup.find_all('ce:label') else '')\n",
    "        \n",
    "        sc_id = soup.find('scopus-id')\n",
    "        \n",
    "        if sc_id:\n",
    "            scopus = requests.get(\"https://api.elsevier.com/content/abstract/scopus_id/{}?apiKey={}\".format(sc_id.get_text(), APIKey))\n",
    "            soup2 = Soup(scopus.content, features=\"lxml\")\n",
    "\n",
    "            data['CitedBy'].append(soup.find('citedby-count').get_text() if soup.find('citedby-count') else '')\n",
    "            data['AuthorAUID'].append('; '.join([auth['auid'] for auth in soup.find_all('author') \n",
    "                                                 if auth.parent.name == 'authors']) if soup.find_all('author') else '')\n",
    "            data['AuthKeywords'].append('; '.join([label.get_text() for label in soup.find_all('author-keyword') \n",
    "                                                 if label.parent.name == 'authkeywords']) \n",
    "                                      if soup.find_all('author-keyword') else '')\n",
    "            data['SubjectAreas'].append('; '.join([label.get_text() for label in soup.find_all('subject-area') \n",
    "                                                 if label.parent.name == 'subject-areas']) \n",
    "                                      if soup.find_all('subject-area') else '')\n",
    "        else:\n",
    "            data['CitedBy'].append('')\n",
    "            data['AuthorAUID'].append('')\n",
    "            data['AuthKeywords'].append('')\n",
    "            data['SubjectAreas'].append('')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data)\n",
    "df.to_csv(os.path.join(os.getcwd(), 'Stakeholders.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
